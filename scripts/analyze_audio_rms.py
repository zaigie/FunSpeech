#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éŸ³é¢‘RMSæ—¶åºåˆ†æžå·¥å…·

ç”¨äºŽåˆ†æžéŸ³é¢‘ï¿½ï¿½ï¿½ä»¶çš„RMSèƒ½é‡ï¼Œå¸®åŠ©ç¡®å®šè¿œåœºè¿‡æ»¤çš„é˜ˆå€¼ã€‚
æ”¯æŒç«‹ä½“å£°ã€å·¦å£°é“ã€å³å£°é“é€‰æ‹©ã€‚
"""

import argparse
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import sys

# è®¾ç½®ä¸­æ–‡æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


def load_audio(file_path: str, channel: str = 'stereo') -> tuple:
    """åŠ è½½éŸ³é¢‘æ–‡ä»¶

    Args:
        file_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        channel: å£°é“é€‰æ‹© ('stereo', 'left', 'right')

    Returns:
        (audio_data, sample_rate): éŸ³é¢‘æ•°æ®å’Œé‡‡æ ·çŽ‡
    """
    file_ext = Path(file_path).suffix.lower()

    if file_ext == '.wav':
        import wave
        with wave.open(file_path, 'rb') as wav_file:
            sample_rate = wav_file.getframerate()
            n_channels = wav_file.getnchannels()
            sample_width = wav_file.getsampwidth()
            n_frames = wav_file.getnframes()

            # è¯»å–éŸ³é¢‘æ•°æ®
            audio_bytes = wav_file.readframes(n_frames)

            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            if sample_width == 2:  # 16-bit
                audio_int = np.frombuffer(audio_bytes, dtype=np.int16)
            elif sample_width == 4:  # 32-bit
                audio_int = np.frombuffer(audio_bytes, dtype=np.int32)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„é‡‡æ ·ä½æ·±: {sample_width}")

            # è½¬æ¢ä¸ºfloat32 (-1.0 to 1.0)
            audio_float = audio_int.astype(np.float32) / (2 ** (8 * sample_width - 1))

            # å¤„ç†å¤šå£°é“
            if n_channels > 1:
                audio_float = audio_float.reshape(-1, n_channels)
                if channel == 'left':
                    audio_float = audio_float[:, 0]
                    print(f"âœ“ ä½¿ç”¨å·¦å£°é“")
                elif channel == 'right':
                    audio_float = audio_float[:, 1]
                    print(f"âœ“ ä½¿ç”¨å³å£°é“")
                else:  # stereo - å¹³å‡
                    audio_float = np.mean(audio_float, axis=1)
                    print(f"âœ“ ä½¿ç”¨ç«‹ä½“å£°ï¼ˆåŒå£°é“å¹³å‡ï¼‰")
            else:
                print(f"âœ“ ä½¿ç”¨å•å£°é“")

            return audio_float, sample_rate

    else:
        # å°è¯•ä½¿ç”¨ soundfile æˆ– librosa
        try:
            import soundfile as sf
            audio_float, sample_rate = sf.read(file_path)

            if len(audio_float.shape) > 1:  # å¤šå£°é“
                if channel == 'left':
                    audio_float = audio_float[:, 0]
                    print(f"âœ“ ä½¿ç”¨å·¦å£°é“")
                elif channel == 'right':
                    audio_float = audio_float[:, 1]
                    print(f"âœ“ ä½¿ç”¨å³å£°é“")
                else:
                    audio_float = np.mean(audio_float, axis=1)
                    print(f"âœ“ ä½¿ç”¨ç«‹ä½“å£°ï¼ˆåŒå£°é“å¹³å‡ï¼‰")
            else:
                print(f"âœ“ ä½¿ç”¨å•å£°é“")

            return audio_float, sample_rate

        except ImportError:
            print("é”™è¯¯: è¯·å®‰è£… soundfile åº“: pip install soundfile")
            sys.exit(1)


def calculate_rms_energy(audio_array: np.ndarray) -> float:
    """è®¡ç®—éŸ³é¢‘RMSèƒ½é‡

    Args:
        audio_array: float32éŸ³é¢‘æ•°ç»„ï¼ŒèŒƒå›´-1.0åˆ°1.0

    Returns:
        RMSèƒ½é‡å€¼
    """
    if len(audio_array) == 0:
        return 0.0
    return float(np.sqrt(np.mean(audio_array ** 2)))


def analyze_rms_timeline(audio_data: np.ndarray, sample_rate: int,
                         chunk_size_ms: int = 240) -> tuple:
    """åˆ†æžéŸ³é¢‘çš„RMSæ—¶åº

    Args:
        audio_data: éŸ³é¢‘æ•°æ®
        sample_rate: é‡‡æ ·çŽ‡
        chunk_size_ms: åˆ†å—å¤§å°ï¼ˆæ¯«ç§’ï¼‰

    Returns:
        (time_points, rms_values): æ—¶é—´ç‚¹å’Œå¯¹åº”çš„RMSå€¼
    """
    chunk_samples = int(sample_rate * chunk_size_ms / 1000)
    n_chunks = len(audio_data) // chunk_samples

    time_points = []
    rms_values = []

    for i in range(n_chunks):
        start_idx = i * chunk_samples
        end_idx = start_idx + chunk_samples
        chunk = audio_data[start_idx:end_idx]

        rms = calculate_rms_energy(chunk)
        time_s = (start_idx + chunk_samples / 2) / sample_rate

        time_points.append(time_s)
        rms_values.append(rms)

    return np.array(time_points), np.array(rms_values)


def print_statistics(rms_values: np.ndarray, threshold: float = 0.01):
    """æ‰“å°RMSç»Ÿè®¡ä¿¡æ¯

    Args:
        rms_values: RMSå€¼æ•°ç»„
        threshold: é˜ˆå€¼
    """
    print("\n" + "="*60)
    print("RMS ç»Ÿè®¡åˆ†æž")
    print("="*60)

    print(f"\nðŸ“Š åŸºç¡€ç»Ÿè®¡:")
    print(f"  - æœ€å°å€¼: {np.min(rms_values):.6f}")
    print(f"  - æœ€å¤§å€¼: {np.max(rms_values):.6f}")
    print(f"  - å¹³å‡å€¼: {np.mean(rms_values):.6f}")
    print(f"  - ä¸­ä½æ•°: {np.median(rms_values):.6f}")
    print(f"  - æ ‡å‡†å·®: {np.std(rms_values):.6f}")

    print(f"\nðŸ“ˆ ç™¾åˆ†ä½æ•°:")
    for p in [10, 25, 50, 75, 90, 95, 99]:
        value = np.percentile(rms_values, p)
        print(f"  - P{p:2d}: {value:.6f}")

    print(f"\nðŸŽ¯ é˜ˆå€¼åˆ†æž (å½“å‰é˜ˆå€¼: {threshold:.6f}):")
    above_threshold = np.sum(rms_values >= threshold)
    below_threshold = np.sum(rms_values < threshold)
    total = len(rms_values)

    print(f"  - è¶…è¿‡é˜ˆå€¼çš„å¸§æ•°: {above_threshold} ({above_threshold/total*100:.1f}%)")
    print(f"  - ä½ŽäºŽé˜ˆå€¼çš„å¸§æ•°: {below_threshold} ({below_threshold/total*100:.1f}%)")

    print(f"\nðŸ’¡ å»ºè®®çš„é˜ˆå€¼èŒƒå›´:")
    # åŸºäºŽéžé›¶RMSå€¼çš„ç»Ÿè®¡
    non_zero_rms = rms_values[rms_values > 0.001]
    if len(non_zero_rms) > 0:
        p10 = np.percentile(non_zero_rms, 10)
        p25 = np.percentile(non_zero_rms, 25)
        mean = np.mean(non_zero_rms)

        print(f"  - ä¿å®ˆæ¨¡å¼ (é«˜çµæ•åº¦): {p10:.6f} (P10)")
        print(f"  - å®½æ¾æ¨¡å¼ (æŽ¨è):     {p25:.6f} (P25)")
        print(f"  - ä¸¥æ ¼æ¨¡å¼ (ä½Žè¯¯è§¦):   {mean*0.5:.6f} (å¹³å‡å€¼çš„50%)")

    print("="*60 + "\n")


def plot_rms_timeline(time_points: np.ndarray, rms_values: np.ndarray,
                      threshold: float = 0.01, save_path: str = None):
    """ç»˜åˆ¶RMSæ—¶åºå›¾

    Args:
        time_points: æ—¶é—´ç‚¹æ•°ç»„
        rms_values: RMSå€¼æ•°ç»„
        threshold: é˜ˆå€¼çº¿
        save_path: ä¿å­˜è·¯å¾„
    """
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))

    # ä¸Šå›¾: RMSæ—¶åº
    ax1.plot(time_points, rms_values, linewidth=1, label='RMS Energy', color='steelblue')
    ax1.axhline(y=threshold, color='red', linestyle='--', linewidth=2,
                label=f'é˜ˆå€¼ = {threshold:.6f}')

    # æ ‡è®°è¶…è¿‡é˜ˆå€¼çš„åŒºåŸŸ
    above_threshold = rms_values >= threshold
    ax1.fill_between(time_points, 0, rms_values, where=above_threshold,
                     alpha=0.3, color='green', label='è¿‘åœºéŸ³é¢‘ (>= é˜ˆå€¼)')
    ax1.fill_between(time_points, 0, rms_values, where=~above_threshold,
                     alpha=0.3, color='red', label='è¿œåœºéŸ³é¢‘ (< é˜ˆå€¼)')

    ax1.set_xlabel('æ—¶é—´ (ç§’)', fontsize=12)
    ax1.set_ylabel('RMS èƒ½é‡', fontsize=12)
    ax1.set_title('éŸ³é¢‘ RMS èƒ½é‡æ—¶åºåˆ†æž', fontsize=14, fontweight='bold')
    ax1.legend(loc='upper right', fontsize=10)
    ax1.grid(True, alpha=0.3)
    ax1.set_ylim(bottom=0)

    # ä¸‹å›¾: RMSåˆ†å¸ƒç›´æ–¹å›¾
    ax2.hist(rms_values, bins=100, color='steelblue', alpha=0.7, edgecolor='black')
    ax2.axvline(x=threshold, color='red', linestyle='--', linewidth=2,
                label=f'é˜ˆå€¼ = {threshold:.6f}')
    ax2.axvline(x=np.mean(rms_values), color='orange', linestyle=':', linewidth=2,
                label=f'å¹³å‡å€¼ = {np.mean(rms_values):.6f}')
    ax2.axvline(x=np.median(rms_values), color='green', linestyle=':', linewidth=2,
                label=f'ä¸­ä½æ•° = {np.median(rms_values):.6f}')

    ax2.set_xlabel('RMS èƒ½é‡', fontsize=12)
    ax2.set_ylabel('å¸§æ•°', fontsize=12)
    ax2.set_title('RMS èƒ½é‡åˆ†å¸ƒç›´æ–¹å›¾', fontsize=14, fontweight='bold')
    ax2.legend(loc='upper right', fontsize=10)
    ax2.grid(True, alpha=0.3, axis='y')

    plt.tight_layout()

    if save_path:
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        print(f"âœ“ å›¾è¡¨å·²ä¿å­˜åˆ°: {save_path}")

    plt.show()


def main():
    parser = argparse.ArgumentParser(
        description='éŸ³é¢‘RMSæ—¶åºåˆ†æžå·¥å…· - å¸®åŠ©ç¡®å®šè¿œåœºè¿‡æ»¤é˜ˆå€¼',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # åˆ†æžç«‹ä½“å£°éŸ³é¢‘ï¼ˆé»˜è®¤ï¼‰
  python analyze_audio_rms.py audio.wav

  # ä»…åˆ†æžå·¦å£°é“
  python analyze_audio_rms.py audio.wav --channel left

  # ä»…åˆ†æžå³å£°é“
  python analyze_audio_rms.py audio.wav --channel right

  # è‡ªå®šä¹‰é˜ˆå€¼å’Œåˆ†å—å¤§å°
  python analyze_audio_rms.py audio.wav --threshold 0.015 --chunk-size 160

  # ä¿å­˜å›¾è¡¨
  python analyze_audio_rms.py audio.wav --output rms_analysis.png
        """
    )

    parser.add_argument('audio_file', type=str,
                       help='éŸ³é¢‘æ–‡ä»¶è·¯å¾„ (æ”¯æŒ WAV, MP3, FLAC ç­‰æ ¼å¼)')
    parser.add_argument('--channel', type=str, choices=['stereo', 'left', 'right'],
                       default='stereo',
                       help='å£°é“é€‰æ‹©: stereo(ç«‹ä½“å£°å¹³å‡), left(å·¦å£°é“), right(å³å£°é“) [é»˜è®¤: stereo]')
    parser.add_argument('--threshold', type=float, default=0.01,
                       help='RMSèƒ½é‡é˜ˆå€¼ [é»˜è®¤: 0.01]')
    parser.add_argument('--chunk-size', type=int, default=240,
                       help='åˆ†å—å¤§å°(æ¯«ç§’) [é»˜è®¤: 240msï¼Œä¸Žæµå¼ASRä¸€è‡´]')
    parser.add_argument('--output', '-o', type=str, default=None,
                       help='ä¿å­˜å›¾è¡¨çš„è·¯å¾„ (ä¾‹å¦‚: output.png)')
    parser.add_argument('--no-plot', action='store_true',
                       help='ä¸æ˜¾ç¤ºå›¾è¡¨ï¼Œä»…è¾“å‡ºç»Ÿè®¡ä¿¡æ¯')

    args = parser.parse_args()

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(args.audio_file).exists():
        print(f"é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨: {args.audio_file}")
        sys.exit(1)

    print("="*60)
    print("éŸ³é¢‘ RMS æ—¶åºåˆ†æžå·¥å…·")
    print("="*60)
    print(f"\nðŸ“ æ–‡ä»¶: {args.audio_file}")
    print(f"ðŸŽšï¸  å£°é“: {args.channel}")
    print(f"ðŸ“Š åˆ†å—å¤§å°: {args.chunk_size}ms")
    print(f"ðŸŽ¯ é˜ˆå€¼: {args.threshold:.6f}")
    print()

    # åŠ è½½éŸ³é¢‘
    print("æ­£åœ¨åŠ è½½éŸ³é¢‘...")
    audio_data, sample_rate = load_audio(args.audio_file, args.channel)
    duration = len(audio_data) / sample_rate

    print(f"âœ“ é‡‡æ ·çŽ‡: {sample_rate} Hz")
    print(f"âœ“ æ—¶é•¿: {duration:.2f} ç§’")
    print(f"âœ“ æ ·æœ¬æ•°: {len(audio_data)}")

    # åˆ†æžRMSæ—¶åº
    print(f"\næ­£åœ¨åˆ†æž RMS æ—¶åº (åˆ†å—å¤§å°: {args.chunk_size}ms)...")
    time_points, rms_values = analyze_rms_timeline(audio_data, sample_rate, args.chunk_size)
    print(f"âœ“ åˆ†æžäº† {len(rms_values)} ä¸ªéŸ³é¢‘å—")

    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print_statistics(rms_values, args.threshold)

    # ç»˜åˆ¶å›¾è¡¨
    if not args.no_plot:
        print("æ­£åœ¨ç”Ÿæˆå›¾è¡¨...")
        plot_rms_timeline(time_points, rms_values, args.threshold, args.output)
    elif args.output:
        print("æ­£åœ¨ä¿å­˜å›¾è¡¨...")
        plot_rms_timeline(time_points, rms_values, args.threshold, args.output)
        # å…³é—­æ˜¾ç¤ºçª—å£
        plt.close()


if __name__ == '__main__':
    main()
